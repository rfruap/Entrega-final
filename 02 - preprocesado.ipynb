{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e817a0c6",
   "metadata": {},
   "source": [
    "⚠️ **Aviso:** Este cuaderno NO requiere login ni API. Solo lee archivos locales.\n",
    "\n",
    "# 02 - preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5599d802",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, pandas as pd\n",
    "\n",
    "def load_table(base_name):\n",
    "    csv_path = os.path.join('.', f'{base_name}.csv')\n",
    "    xlsx_path = os.path.join('.', f'{base_name}.xlsx')\n",
    "    if os.path.exists(csv_path):\n",
    "        return pd.read_csv(csv_path), csv_path\n",
    "    elif os.path.exists(xlsx_path):\n",
    "        return pd.read_excel(xlsx_path), xlsx_path\n",
    "    else:\n",
    "        raise FileNotFoundError(f'No se encontró {base_name}.csv ni {base_name}.xlsx en la carpeta del notebook.')\n",
    "\n",
    "def detect_id(df):\n",
    "    for c in df.columns:\n",
    "        name = c.lower()\n",
    "        if name == 'id' or 'documento' in name or 'cedul' in name or 'identific' in name or 'codigo' in name or 'código' in name:\n",
    "            return c\n",
    "    return 'ID' if 'ID' in df.columns else df.columns[0]\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "train, train_path = load_table('train')\n",
    "print('Usando:', train_path, '| shape:', train.shape)\n",
    "\n",
    "try:\n",
    "    test, test_path = load_table('test')\n",
    "    print('Usando:', test_path, '| shape:', test.shape)\n",
    "except FileNotFoundError:\n",
    "    test = None\n",
    "    print('test no encontrado (opcional).')\n",
    "\n",
    "ID_COL = detect_id(train)\n",
    "TARGET  = 'RENDIMIENTO_GLOBAL' if 'RENDIMIENTO_GLOBAL' in train.columns else None\n",
    "\n",
    "if TARGET:\n",
    "    y = (train[TARGET].astype(str).str.strip().str.lower()\n",
    "         .replace({'medio bajo':'medio-bajo','medio alto':'medio-alto'}))\n",
    "    X = train.drop(columns=[TARGET])\n",
    "else:\n",
    "    y = None; X = train.copy()\n",
    "\n",
    "cat_cols = [c for c in X.columns if X[c].dtype == 'object']\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "print(f'ID_COL: {ID_COL} | TARGET: {TARGET} | cat_cols={len(cat_cols)} | num_cols={len(num_cols)}')\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    ('cat', Pipeline([('imp', SimpleImputer(strategy='most_frequent')),\n",
    "                      ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False))]), cat_cols),\n",
    "    ('num', Pipeline([('imp', SimpleImputer(strategy='median'))]), num_cols)\n",
    "])\n",
    "\n",
    "preprocess.fit(X)\n",
    "X_tr = preprocess.transform(X)\n",
    "print('X_preprocesado (train):', X_tr.shape)\n",
    "if test is not None:\n",
    "    X_te = preprocess.transform(test)\n",
    "    print('X_preprocesado (test):', X_te.shape)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
